# LLM Qunatization and Inferencing Tool
This repository houses a Python tool designed to qunatize a large language model using different algorithms like BitsandByets, Llama.cpp, AWQ, and Exllamv2.  The repository also helps in storing these quantized model on HuggingFace hub.
The tool also helps in using quantized models for inferencing tasks. 
 *This tool is intended for education and informational purposes only. Please use quantized model in production with caution after proper testing. * 

## Features

- **Qunatization**: The notebook covers different algorithms to quantize large language model.
- **Inferencing**: The notebook covers inferencing using different qunatized model.


## How to use - 
- **Install required libraries**: use pip install section to install required python packages to run the program.
- **HuggingFace Hub API key**: HuggingFace hub API key is needed to access gater LLM models, to create a model repo, and push the quantized model to the repo. 
- **How to run**: You can run specific section of the notebook relevant for qunatization algorithms.
